{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T07:28:25.262348Z",
     "start_time": "2024-10-27T07:28:25.239380100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.visualization import plot_prediction_vs_real\n",
    "from experiments.graphs.graph_experiments import get_pignn_config, get_dataset, create_data_loaders\n",
    "from architecture.pignn.pignn import FlowPIGNN\n",
    "from architecture.pignn.deconv import DeConvNet, FCDeConvNet\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Evaluation methods for non-temporal methods\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def calculate_test_loss(model, test_loader, plot_examples=False):\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            x = batch.x.to(device).float()\n",
    "            pos = batch.pos.to(device).float()\n",
    "            ef = batch.edge_attr.to(device).float()\n",
    "            gf = batch.global_feats.to(device).float()\n",
    "            batch_size = gf.size(0)\n",
    "\n",
    "            if isinstance(model, FCDeConvNet):\n",
    "                x_cat = torch.cat((\n",
    "                    x.reshape(batch_size, -1),\n",
    "                    pos.reshape(batch_size, -1),\n",
    "                    ef.reshape(batch_size, -1),\n",
    "                    gf.reshape(batch_size, -1)\n",
    "                ), dim=-1)\n",
    "\n",
    "                pred = model(x_cat).float()\n",
    "                target = batch.y.to(device).reshape(-1, pred.size(1))\n",
    "            else:\n",
    "                pred = model(batch, torch.cat((x, pos), dim=-1), ef, gf)\n",
    "                target = batch.y.to(device).reshape(-1, pred.size(1))\n",
    "            test_loss = criterion(pred, target)\n",
    "\n",
    "            if plot_examples:\n",
    "                predictions = [\n",
    "                    pred[0, :].reshape(128, 128).cpu(),\n",
    "                    pred[16, :].reshape(128, 128).cpu(),\n",
    "                    pred[32, :].reshape(128, 128).cpu()\n",
    "                ]\n",
    "\n",
    "                targets = [\n",
    "                    target[0, :].reshape(128, 128).cpu(),\n",
    "                    target[16, :].reshape(128, 128).cpu(),\n",
    "                    target[32, :].reshape(128, 128).cpu()\n",
    "                ]\n",
    "                for i in range(3):\n",
    "                    plot_prediction_vs_real(predictions[i], targets[i], number=i+3)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        return np.mean(test_losses), np.std(test_losses)\n",
    "\n",
    "def evaluate_model(experiment_dir):\n",
    "    config_path = os.path.join(experiment_dir, 'config.json')\n",
    "    model_config = get_pignn_config()\n",
    "    config = load_config(config_path)\n",
    "    model = FlowPIGNN(**model_config, deconv_model=DeConvNet(1, [64, 128, 256, 1], output_size=128)).to(device) if config['use_graph'] else FCDeConvNet(212, 650, 656, 500).to(device)\n",
    "    model_path = os.path.join(experiment_dir, 'pignn_best.pt')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    dataset = get_dataset(config['dataset_dirs'], False, 1)\n",
    "    _, _, test_loader = create_data_loaders(dataset, config['batch_size'], 1)\n",
    "    return calculate_test_loss(model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T07:28:42.384425400Z",
     "start_time": "2024-10-27T07:28:25.527161300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate non-temporal methods\n",
    "base_dir = \"results\"\n",
    "\n",
    "for experiment_name in os.listdir(base_dir):\n",
    "    experiment_dir = os.path.join(base_dir, experiment_name)\n",
    "\n",
    "    if os.path.isdir(experiment_dir):  # Check if it's a directory\n",
    "        try:\n",
    "            mse, std = evaluate_model(experiment_dir)\n",
    "            print(f\"Loaded model from {experiment_name} has MSE on test set: {mse} +- {std}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model from {experiment_name}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from architecture.windspeedLSTM.windspeedLSTM import WindSpeedLSTMDeConv, WindspeedLSTM\n",
    "\n",
    "# Evaluation methods for temporal methods\n",
    "def evaluate_temporal_model(experiment_dir):\n",
    "    config_path = os.path.join(experiment_dir, 'config.json')\n",
    "    model_config = get_pignn_config()\n",
    "    config = load_config(config_path)\n",
    "    is_direct_lstm = config['direct_lstm']\n",
    "\n",
    "    deconv_model = DeConvNet(1, [64, 128, 256, 1], output_size=image_size) if not is_direct_lstm else None\n",
    "    graph_model = FlowPIGNN(**model_config, deconv_model=deconv_model).to(device)\n",
    "    graph_model_path = os.path.join(experiment_dir, 'pignn_best.pt')\n",
    "    graph_model.load_state_dict(torch.load(graph_model_path))\n",
    "\n",
    "    temporal_model = WindSpeedLSTMDeConv(seq_length, [64, 128, 256, 1], image_size).to(\n",
    "        device) if is_direct_lstm else WindspeedLSTM(seq_length).to(device)\n",
    "    temporal_model_path = os.path.join(experiment_dir, 'unet_lstm_best.pt')\n",
    "    temporal_model.load_state_dict(torch.load(temporal_model_path))\n",
    "    embedding_size = (50, 10) if is_direct_lstm else (image_size, image_size)\n",
    "\n",
    "    dataset = get_dataset(config['dataset_dirs'], True, seq_length)\n",
    "    _, _, test_loader = create_data_loaders(dataset, config['batch_size'], seq_length)\n",
    "    return calculate_temporal_test_loss(test_loader, graph_model, temporal_model, embedding_size)\n",
    "\n",
    "def calculate_temporal_test_loss(test_loader, graph_model, temporal_model, embedding_size, output_size=(128, 128), plot_examples=False):\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for j, batch in enumerate(test_loader):\n",
    "            generated_img = []\n",
    "            target_img = []\n",
    "            for i, seq in enumerate(batch[0]):\n",
    "                # Process graphs in parallel at each timestep for the entire batch\n",
    "                seq = seq.to(device)\n",
    "                nf = torch.cat((seq.x.to(device), seq.pos.to(device)), dim=-1).float()\n",
    "                ef = seq.edge_attr.to(device).float()\n",
    "                gf = seq.global_feats.to(device).float()\n",
    "                graph_output = graph_model(seq, nf, ef, gf).reshape(-1, embedding_size[0], embedding_size[1])\n",
    "                generated_img.append(graph_output)\n",
    "                target_img.append(batch[1][i].y.to(device).reshape(-1, output_size[0], output_size[1]))\n",
    "\n",
    "            temporal_img = torch.stack(generated_img, dim=1)\n",
    "            output = temporal_model(temporal_img).flatten()\n",
    "            target = torch.stack(target_img, dim=1).flatten()\n",
    "            test_loss = criterion(output, target)\n",
    "\n",
    "            if plot_examples:\n",
    "                plot_prediction_vs_real(output[0, seq_length - 1].cpu(), target[0, seq_length - 1].cpu(), number=j+6)\n",
    "            test_losses.append(test_loss.item())\n",
    "    return np.mean(test_losses), np.std(test_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T07:35:03.714595600Z",
     "start_time": "2024-10-27T07:35:03.678624700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matth\\AppData\\Local\\Temp\\ipykernel_29100\\86000758.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_model.load_state_dict(torch.load(graph_model_path))\n",
      "C:\\Users\\Matth\\AppData\\Local\\Temp\\ipykernel_29100\\86000758.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  temporal_model.load_state_dict(torch.load(temporal_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets, 2300 samples\n",
      "Loaded model from 20241026180328_Case01_False_pignn_unet_lstm_30_50_case_01_sliding has MSE on test set: 0.25863130403601603 +- 0.021885890681178796\n",
      "Loaded datasets, 2300 samples\n",
      "Loaded model from 20241026232226_Case01_False_pignn_lstm_deconv_30_50_case_01_sliding has MSE on test set: 0.26188334498716437 +- 0.023512369145551625\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for temporal methods\n",
    "image_size = 128\n",
    "seq_length = 50\n",
    "base_dir = \"results/temporal\"\n",
    "\n",
    "# Iterate through each experiment folder and load the model and config\n",
    "for experiment_name in os.listdir(base_dir):\n",
    "    experiment_dir = os.path.join(base_dir, experiment_name)\n",
    "\n",
    "    if os.path.isdir(experiment_dir):\n",
    "        try:\n",
    "            mse, std = evaluate_temporal_model(experiment_dir)\n",
    "            print(f\"Loaded model from {experiment_name} has MSE on test set: {mse} +- {std}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model from {experiment_name}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-27T07:43:04.476053300Z",
     "start_time": "2024-10-27T07:35:04.118833700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
