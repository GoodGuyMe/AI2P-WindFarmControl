{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from sim_to_speed_map.nets.pignn import PowerPIGNN\n",
    "from utils import read_wind_angles, read_turbine_positions, read_measurement, get_wind_angles_for_range\n",
    "\n",
    "# import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from adamp import AdamP\n",
    "# from dgl.data.utils import load_graphs\n",
    "from torch.optim import Adam\n",
    "from box import Box\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T13:11:44.581473200Z",
     "start_time": "2024-09-18T13:11:42.318609600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T12:57:33.314921Z",
     "start_time": "2024-09-18T12:57:33.312923400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    nf_dim = 3\n",
    "    ef_dim = 2\n",
    "    u_dim = 1\n",
    "\n",
    "    cfg = Box({\n",
    "        'model': {\n",
    "            'edge_in_dim': ef_dim,\n",
    "            'node_in_dim': nf_dim,\n",
    "            'global_in_dim': u_dim,\n",
    "            'n_pign_layers': 3,\n",
    "            'edge_hidden_dim': 50,\n",
    "            'node_hidden_dim': 50,\n",
    "            'global_hidden_dim': 50,\n",
    "            'residual': True,\n",
    "            'input_norm': True,\n",
    "            'pign_mlp_params': {'num_neurons': [256, 128],\n",
    "                               'hidden_act': 'ReLU',\n",
    "                               'out_act': 'ReLU'},\n",
    "            'reg_mlp_params': {'num_neurons': [64, 32, 16],\n",
    "                               'hidden_act': 'ReLU',\n",
    "                               'out_act': 'ReLU'},\n",
    "            'pign_params': {'edge_aggregator': 'mean',\n",
    "                           'global_node_aggr': 'mean',\n",
    "                           'global_edge_aggr': 'mean'}\n",
    "        },\n",
    "        'train': {\n",
    "            'batch_size': 512,\n",
    "            'reset_g_every': 64,\n",
    "            'num_procs': 6,\n",
    "            'log_every': 100,\n",
    "            'train_steps': 20000,\n",
    "        }\n",
    "    })\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# TODO: import the data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T13:28:24.453158500Z",
     "start_time": "2024-09-18T13:28:23.883688400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = get_config()\n",
    "\n",
    "    # prepare validation data\n",
    "    val_gs, labels = load_graphs('val_gs3.bin')\n",
    "    val_us = labels['global_feat']\n",
    "    val_us = val_us.to(device)\n",
    "    val_gs = dgl.batch(val_gs).to(device)\n",
    "\n",
    "    model = PowerPIGNN(**config.model).to(device)\n",
    "    print(model)\n",
    "\n",
    "    if 'cuda' in device:\n",
    "        optimizer = AdamP(model.parameters(), lr=1e-3)\n",
    "    else:  # for some reason, the entire training code with adamp optimizer broken on cpu\n",
    "        optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50)\n",
    "\n",
    "    n_update = 0\n",
    "    for epoch in range(config.train.train_steps):\n",
    "        if n_update % config.train.reset_g_every == 0:\n",
    "            gs, us = prepare_data(config.train.batch_size)\n",
    "            gs = dgl.batch(gs)\n",
    "            us = torch.stack(us)\n",
    "\n",
    "        gs = gs.to(device)\n",
    "        us = us.to(device)\n",
    "\n",
    "        nf, ef = gs.ndata['feat'], gs.edata['feat']\n",
    "        # Augment Euclidean coordinates\n",
    "        nf = torch.cat([nf, gs.ndata['x'], gs.ndata['y']], dim=-1)\n",
    "\n",
    "        pred = model(gs, nf, ef, us)\n",
    "        loss = criterion(pred, gs.ndata['power'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        n_update += 1\n",
    "\n",
    "        if n_update % config.train.log_every == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                val_nf, val_ef = val_gs.ndata['feat'], val_gs.edata['feat']\n",
    "                val_nf = torch.cat([val_nf, val_gs.ndata['x'], val_gs.ndata['y']], dim=-1)\n",
    "                val_pred = model(val_gs, val_nf, val_ef, val_us)\n",
    "                val_loss = criterion(val_pred, val_gs.ndata['power'])\n",
    "                model.train()\n",
    "\n",
    "            print(f\"step {n_update}/{config.train.train_steps}, lr: {learning_rate}, training loss: {loss}, validation loss: {val_loss}\")\n",
    "\n",
    "        # save model pointer\n",
    "        torch.save(model.state_dict(), f\"sim_to_speed_map_{epoch}.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
